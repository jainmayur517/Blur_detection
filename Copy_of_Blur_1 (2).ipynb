{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CVhE01X5R_xW"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "from torch.autograd import Function\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import copy\n",
    "import time\n",
    "from torchvision.utils import save_image\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "wQpiKMhmR_xa",
    "outputId": "b2d813a1-56f5-414a-c74d-f2057440e3c6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available!\n"
     ]
    }
   ],
   "source": [
    "apply_transform = transforms.Compose([transforms.Resize([256,256]),transforms.ToTensor()])\n",
    "apply_transform0 = transforms.Compose([transforms.Resize([256,256]),transforms.ToTensor()])\n",
    "apply_transform1 = transforms.Compose([transforms.Resize([128,128]),transforms.ToTensor()])\n",
    "apply_transform2 = transforms.Compose([transforms.Resize([64,64]),transforms.ToTensor()])\n",
    "apply_transform3 = transforms.Compose([transforms.Resize([32,32]),transforms.ToTensor()])\n",
    "\n",
    "use_gpu = torch.cuda.is_available()\n",
    "if use_gpu:\n",
    "    print('GPU is available!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ir8gG2uNR_xd",
    "outputId": "3a02d9e2-defb-47e5-cb08-21b8804c0804"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "979\n"
     ]
    }
   ],
   "source": [
    "image_path = '/home/cvgws2/juniors_blur/dataset_arch_3/image'\n",
    "ground_path = '/home/cvgws2/juniors_blur/dataset_arch_3/gt'\n",
    "train_ = []\n",
    "print(len(os.listdir(image_path)))\n",
    "for i in os.listdir(image_path):\n",
    "    ii , iii = map(str,i.split('.'))\n",
    "    a = Image.open(os.path.join(image_path,i))\n",
    "    a = apply_transform(a)\n",
    "    x = Image.open(os.path.join(ground_path,ii+'.png'))\n",
    "    b = apply_transform(x)\n",
    "    c = apply_transform1(x)\n",
    "    d = apply_transform2(x)\n",
    "    e = apply_transform3(x)\n",
    "    train_.append([a,b,c,d,e])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kUYR8QPQIoy5"
   },
   "outputs": [],
   "source": [
    "image_path = '/content/gdrive/My Drive/Colab Notebooks/dataset/Nonblur'\n",
    "ground_path = '/content/gdrive/My Drive/Colab Notebooks/dataset/image_screenshot_17.11.2019.png'\n",
    "for i in os.listdir(image_path):\n",
    "    ii , iii = map(str,i.split('.'))\n",
    "    a = Image.open(os.path.join(image_path,i))\n",
    "    a = apply_transform(a)\n",
    "    x = Image.open(ground_path)\n",
    "    b = apply_transform(x)\n",
    "    c = apply_transform1(x)\n",
    "    d = apply_transform2(x)\n",
    "    e = apply_transform3(x)\n",
    "    train_.append([a,b,c,d,e])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aBhlZFntu18P"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "random.shuffle(train_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CxWWQDrjR_xh"
   },
   "outputs": [],
   "source": [
    "class BasicConv2d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, **kwargs):\n",
    "        super(BasicConv2d, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, bias=False, **kwargs)\n",
    "        self.bn = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        return F.relu(x, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Mn1JGX9uR_xj"
   },
   "outputs": [],
   "source": [
    "class BasicConvTranspose2d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, **kwargs):\n",
    "        super(BasicConvTranspose2d, self).__init__()\n",
    "        self.conv = nn.ConvTranspose2d(in_channels, out_channels, bias=False, **kwargs)\n",
    "        self.bn = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        return F.relu(x, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 992
    },
    "colab_type": "code",
    "id": "RTCJRCkAR_xm",
    "outputId": "e2e6475b-7039-48fc-99cb-7819cc3ab16a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN_model(\n",
      "  (conv1): Sequential(\n",
      "    (0): BasicConv2d(\n",
      "      (conv): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (conv2): Sequential(\n",
      "    (0): BasicConv2d(\n",
      "      (conv): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (conv3): Sequential(\n",
      "    (0): BasicConv2d(\n",
      "      (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (conv4): Sequential(\n",
      "    (0): BasicConv2d(\n",
      "      (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (deconv1): Sequential(\n",
      "    (0): BasicConvTranspose2d(\n",
      "      (conv): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False)\n",
      "      (bn): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (deconv2): Sequential(\n",
      "    (0): BasicConvTranspose2d(\n",
      "      (conv): ConvTranspose2d(64, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False)\n",
      "      (bn): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (deconv3): Sequential(\n",
      "    (0): BasicConvTranspose2d(\n",
      "      (conv): ConvTranspose2d(32, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False)\n",
      "      (bn): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (deconv4): Sequential(\n",
      "    (0): BasicConvTranspose2d(\n",
      "      (conv): ConvTranspose2d(16, 3, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False)\n",
      "      (bn): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (conv1x1_1): Conv2d(16, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (conv1x1_2): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (conv1x1_3): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (conv1x1_4): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (conv1x1_o1): Conv2d(3, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class NN_model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NN_model,self).__init__()\n",
    "        self.conv1=nn.Sequential(BasicConv2d(3,16,kernel_size=3,padding=1,stride=2))\n",
    "\n",
    "        self.conv2=nn.Sequential(BasicConv2d(16,32,kernel_size=3,padding=1,stride=2))\n",
    "        #self.maxpool=nn.MaxPool2d(2,2)\n",
    "        self.conv3=nn.Sequential(BasicConv2d(32,64,kernel_size=3,padding=1,stride=2))\n",
    "        #self.maxpool=nn.MaxPool2d(2,2)\n",
    "        self.conv4=nn.Sequential(BasicConv2d(64,128,kernel_size=3,padding=1,stride=2))\n",
    "\n",
    "        self.deconv1=nn.Sequential(BasicConvTranspose2d(128,64,kernel_size=3,padding=1,output_padding = 1,stride=2))\n",
    "\n",
    "        self.deconv2=nn.Sequential(BasicConvTranspose2d(64,32,kernel_size=3,padding=1,output_padding = 1,stride=2)) \n",
    "        \n",
    "        self.deconv3=nn.Sequential(BasicConvTranspose2d(32,16,kernel_size=3,padding=1,output_padding = 1,stride=2))\n",
    "        \n",
    "        self.deconv4=nn.Sequential(BasicConvTranspose2d(16,3,kernel_size=3,padding=1,output_padding = 1,stride=2)) \n",
    "        \n",
    "        self.conv1x1_1= nn.Conv2d(16,1,kernel_size = 1,padding=0,stride = 1)\n",
    "        self.conv1x1_2= nn.Conv2d(32,1,kernel_size = 1,padding=0,stride = 1)\n",
    "        self.conv1x1_3= nn.Conv2d(64,1,kernel_size = 1,padding=0,stride = 1)\n",
    "        self.conv1x1_4= nn.Conv2d(128,1,kernel_size = 1,padding=0,stride = 1)\n",
    "        self.conv1x1_o1= nn.Conv2d(3,1,kernel_size = 1,padding=0,stride = 1)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        r1 = self.conv1(x)\n",
    "        r2 = self.conv2(r1)\n",
    "        r3 = self.conv3(r2)\n",
    "        x = self.conv4(r3)\n",
    "        \n",
    "        r1 = self.conv1x1_1(r1)\n",
    "        r2 = self.conv1x1_2(r2)\n",
    "        r3 = self.conv1x1_3(r3)\n",
    "        r4 = self.conv1x1_4(x)\n",
    "        x = x+r4\n",
    "        r4 = self.deconv1(x)\n",
    "        x = r4 + r3\n",
    "        r3 = self.deconv2(x)\n",
    "        x = r3+r2\n",
    "        r2 = self.deconv3(x)\n",
    "        x = r2+r1\n",
    "        r1 = self.deconv4(x)\n",
    "        r1 = self.conv1x1_o1(r1)\n",
    "        r2 = self.conv1x1_1(r2)\n",
    "        r3 = self.conv1x1_2(r3)\n",
    "        r4 = self.conv1x1_3(r4)\n",
    "        return r1,r2,r3,r4\n",
    "\n",
    "haha = NN_model()\n",
    "if use_gpu:\n",
    "    haha = haha.cuda()\n",
    "print(haha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "et_NaQgU9BKV"
   },
   "outputs": [],
   "source": [
    "trainLoader = torch.utils.data.DataLoader(train_, batch_size=10,shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ABMeRhBt2Puc"
   },
   "outputs": [],
   "source": [
    "haha = torch.load('./blur1.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vTUfRSToR_xp"
   },
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(haha.parameters(),lr = 1e-3)\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mLlUajOYR_xs"
   },
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    train_loss = 0\n",
    "    start = time.time()\n",
    "    for i in train_:\n",
    "        data,gt1,gt2,gt3,gt4 = i\n",
    "        if use_gpu:\n",
    "            data = data.cuda()\n",
    "            gt1 = gt1.cuda()\n",
    "            gt2 = gt2.cuda()\n",
    "            gt3 = gt3.cuda()\n",
    "            gt4 = gt4.cuda()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        o1,o2,o3,o4= haha(data.unsqueeze(0))\n",
    "        loss = criterion(o1,gt1.unsqueeze(0)) \n",
    "        loss += criterion(o2,gt2.unsqueeze(0))\n",
    "        loss += criterion(o3,gt3.unsqueeze(0))\n",
    "        loss += criterion(o4,gt4.unsqueeze(0))\n",
    "        loss.backward()\n",
    "        train_loss += loss.item()\n",
    "        optimizer.step()\n",
    "    endt = time.time() - start\n",
    "    print('====> Epoch: {} Average loss: {:.4f} Time : {:.0f}m {:.0f}s'.format(epoch, train_loss/len(train_),endt//60,endt%60))\n",
    "    train_losses.append(train_loss / (len(train_)))\n",
    "    return train_loss / (len(train_))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "dy7sYks1R_xu",
    "outputId": "d634f957-e3b6-4a2d-8b0f-24ccf5f31ac2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 0 Average loss: 0.0514 Time : 0m 13s\n",
      "====> Epoch: 1 Average loss: 0.0518 Time : 0m 13s\n",
      "====> Epoch: 2 Average loss: 0.0506 Time : 0m 13s\n",
      "====> Epoch: 3 Average loss: 0.0499 Time : 0m 10s\n",
      "====> Epoch: 4 Average loss: 0.0503 Time : 0m 9s\n",
      "====> Epoch: 5 Average loss: 0.0516 Time : 0m 12s\n",
      "====> Epoch: 6 Average loss: 0.0496 Time : 0m 13s\n",
      "====> Epoch: 7 Average loss: 0.0491 Time : 0m 11s\n",
      "====> Epoch: 8 Average loss: 0.0505 Time : 0m 13s\n",
      "====> Epoch: 9 Average loss: 0.0515 Time : 0m 14s\n",
      "====> Epoch: 10 Average loss: 0.0510 Time : 0m 13s\n",
      "====> Epoch: 11 Average loss: 0.0527 Time : 0m 15s\n",
      "====> Epoch: 12 Average loss: 0.0491 Time : 0m 15s\n",
      "====> Epoch: 13 Average loss: 0.0497 Time : 0m 14s\n",
      "====> Epoch: 14 Average loss: 0.0498 Time : 0m 15s\n",
      "====> Epoch: 15 Average loss: 0.0524 Time : 0m 15s\n",
      "====> Epoch: 16 Average loss: 0.0496 Time : 0m 12s\n",
      "====> Epoch: 17 Average loss: 0.0501 Time : 0m 15s\n",
      "====> Epoch: 18 Average loss: 0.0500 Time : 0m 14s\n",
      "====> Epoch: 19 Average loss: 0.0502 Time : 0m 15s\n",
      "====> Epoch: 20 Average loss: 0.0522 Time : 0m 15s\n",
      "====> Epoch: 21 Average loss: 0.0509 Time : 0m 15s\n",
      "====> Epoch: 22 Average loss: 0.0490 Time : 0m 12s\n",
      "====> Epoch: 23 Average loss: 0.0483 Time : 0m 11s\n",
      "====> Epoch: 24 Average loss: 0.0503 Time : 0m 15s\n",
      "====> Epoch: 25 Average loss: 0.0502 Time : 0m 15s\n",
      "====> Epoch: 26 Average loss: 0.0515 Time : 0m 15s\n",
      "====> Epoch: 27 Average loss: 0.0498 Time : 0m 15s\n",
      "====> Epoch: 28 Average loss: 0.0509 Time : 0m 15s\n",
      "====> Epoch: 29 Average loss: 0.0494 Time : 0m 15s\n",
      "====> Epoch: 30 Average loss: 0.0539 Time : 0m 15s\n",
      "====> Epoch: 31 Average loss: 0.0485 Time : 0m 15s\n",
      "====> Epoch: 32 Average loss: 0.0493 Time : 0m 12s\n",
      "====> Epoch: 33 Average loss: 0.0501 Time : 0m 15s\n",
      "====> Epoch: 34 Average loss: 0.0534 Time : 0m 14s\n",
      "====> Epoch: 35 Average loss: 0.0491 Time : 0m 15s\n",
      "====> Epoch: 36 Average loss: 0.0519 Time : 0m 15s\n",
      "====> Epoch: 37 Average loss: 0.0507 Time : 0m 15s\n",
      "====> Epoch: 38 Average loss: 0.0490 Time : 0m 15s\n",
      "====> Epoch: 39 Average loss: 0.0502 Time : 0m 15s\n",
      "====> Epoch: 40 Average loss: 0.0493 Time : 0m 15s\n",
      "====> Epoch: 41 Average loss: 0.0491 Time : 0m 15s\n",
      "====> Epoch: 42 Average loss: 0.0487 Time : 0m 15s\n",
      "====> Epoch: 43 Average loss: 0.0521 Time : 0m 15s\n",
      "====> Epoch: 44 Average loss: 0.0513 Time : 0m 15s\n",
      "====> Epoch: 45 Average loss: 0.0498 Time : 0m 15s\n",
      "====> Epoch: 46 Average loss: 0.0486 Time : 0m 15s\n",
      "====> Epoch: 47 Average loss: 0.0487 Time : 0m 15s\n",
      "====> Epoch: 48 Average loss: 0.0528 Time : 0m 15s\n",
      "====> Epoch: 49 Average loss: 0.0508 Time : 0m 15s\n",
      "====> Epoch: 50 Average loss: 0.0480 Time : 0m 15s\n",
      "====> Epoch: 51 Average loss: 0.0503 Time : 0m 15s\n",
      "====> Epoch: 52 Average loss: 0.0507 Time : 0m 15s\n",
      "====> Epoch: 53 Average loss: 0.0490 Time : 0m 15s\n",
      "====> Epoch: 54 Average loss: 0.0506 Time : 0m 15s\n",
      "====> Epoch: 55 Average loss: 0.0480 Time : 0m 15s\n",
      "====> Epoch: 56 Average loss: 0.0496 Time : 0m 15s\n",
      "====> Epoch: 57 Average loss: 0.0502 Time : 0m 15s\n",
      "====> Epoch: 58 Average loss: 0.0508 Time : 0m 15s\n",
      "====> Epoch: 59 Average loss: 0.0494 Time : 0m 15s\n",
      "====> Epoch: 60 Average loss: 0.0492 Time : 0m 12s\n",
      "====> Epoch: 61 Average loss: 0.0501 Time : 0m 10s\n",
      "====> Epoch: 62 Average loss: 0.0510 Time : 0m 15s\n",
      "====> Epoch: 63 Average loss: 0.0490 Time : 0m 15s\n",
      "====> Epoch: 64 Average loss: 0.0482 Time : 0m 15s\n",
      "====> Epoch: 65 Average loss: 0.0538 Time : 0m 15s\n",
      "====> Epoch: 66 Average loss: 0.0479 Time : 0m 15s\n",
      "====> Epoch: 67 Average loss: 0.0480 Time : 0m 9s\n",
      "====> Epoch: 68 Average loss: 0.0493 Time : 0m 9s\n",
      "====> Epoch: 69 Average loss: 0.0540 Time : 0m 9s\n",
      "====> Epoch: 70 Average loss: 0.0496 Time : 0m 9s\n",
      "====> Epoch: 71 Average loss: 0.0470 Time : 0m 13s\n",
      "====> Epoch: 72 Average loss: 0.0482 Time : 0m 9s\n",
      "====> Epoch: 73 Average loss: 0.0501 Time : 0m 9s\n",
      "====> Epoch: 74 Average loss: 0.0510 Time : 0m 9s\n",
      "====> Epoch: 75 Average loss: 0.0532 Time : 0m 9s\n",
      "====> Epoch: 76 Average loss: 0.0481 Time : 0m 12s\n",
      "====> Epoch: 77 Average loss: 0.0477 Time : 0m 9s\n",
      "====> Epoch: 78 Average loss: 0.0487 Time : 0m 9s\n",
      "====> Epoch: 79 Average loss: 0.0509 Time : 0m 12s\n",
      "====> Epoch: 80 Average loss: 0.0487 Time : 0m 9s\n",
      "====> Epoch: 81 Average loss: 0.0478 Time : 0m 9s\n",
      "====> Epoch: 82 Average loss: 0.0497 Time : 0m 12s\n",
      "====> Epoch: 83 Average loss: 0.0548 Time : 0m 14s\n",
      "====> Epoch: 84 Average loss: 0.0496 Time : 0m 15s\n",
      "====> Epoch: 85 Average loss: 0.0487 Time : 0m 14s\n",
      "====> Epoch: 86 Average loss: 0.0473 Time : 0m 14s\n",
      "====> Epoch: 87 Average loss: 0.0513 Time : 0m 13s\n",
      "====> Epoch: 88 Average loss: 0.0529 Time : 0m 12s\n",
      "====> Epoch: 89 Average loss: 0.0480 Time : 0m 14s\n",
      "====> Epoch: 90 Average loss: 0.0476 Time : 0m 12s\n",
      "====> Epoch: 91 Average loss: 0.0489 Time : 0m 13s\n",
      "====> Epoch: 92 Average loss: 0.0498 Time : 0m 13s\n",
      "====> Epoch: 93 Average loss: 0.0546 Time : 0m 13s\n",
      "====> Epoch: 94 Average loss: 0.0491 Time : 0m 14s\n",
      "====> Epoch: 95 Average loss: 0.0465 Time : 0m 13s\n",
      "====> Epoch: 96 Average loss: 0.0507 Time : 0m 13s\n",
      "====> Epoch: 97 Average loss: 0.0511 Time : 0m 13s\n",
      "====> Epoch: 98 Average loss: 0.0467 Time : 0m 13s\n",
      "====> Epoch: 99 Average loss: 0.0469 Time : 0m 13s\n",
      "====> Epoch: 100 Average loss: 0.0517 Time : 0m 13s\n",
      "====> Epoch: 101 Average loss: 0.0507 Time : 0m 13s\n",
      "====> Epoch: 102 Average loss: 0.0509 Time : 0m 13s\n",
      "====> Epoch: 103 Average loss: 0.0483 Time : 0m 9s\n",
      "====> Epoch: 104 Average loss: 0.0494 Time : 0m 11s\n",
      "====> Epoch: 105 Average loss: 0.0498 Time : 0m 11s\n",
      "====> Epoch: 106 Average loss: 0.0477 Time : 0m 13s\n",
      "====> Epoch: 107 Average loss: 0.0472 Time : 0m 14s\n",
      "====> Epoch: 108 Average loss: 0.0516 Time : 0m 14s\n",
      "====> Epoch: 109 Average loss: 0.0514 Time : 0m 9s\n",
      "====> Epoch: 110 Average loss: 0.0497 Time : 0m 12s\n",
      "====> Epoch: 111 Average loss: 0.0474 Time : 0m 15s\n",
      "====> Epoch: 112 Average loss: 0.0491 Time : 0m 15s\n",
      "====> Epoch: 113 Average loss: 0.0477 Time : 0m 15s\n",
      "====> Epoch: 114 Average loss: 0.0489 Time : 0m 15s\n",
      "====> Epoch: 115 Average loss: 0.0484 Time : 0m 15s\n",
      "====> Epoch: 116 Average loss: 0.0485 Time : 0m 15s\n",
      "====> Epoch: 117 Average loss: 0.0483 Time : 0m 11s\n",
      "====> Epoch: 118 Average loss: 0.0516 Time : 0m 9s\n",
      "====> Epoch: 119 Average loss: 0.0484 Time : 0m 9s\n",
      "====> Epoch: 120 Average loss: 0.0497 Time : 0m 9s\n",
      "====> Epoch: 121 Average loss: 0.0519 Time : 0m 9s\n",
      "====> Epoch: 122 Average loss: 0.0480 Time : 0m 9s\n",
      "====> Epoch: 123 Average loss: 0.0464 Time : 0m 9s\n",
      "====> Epoch: 124 Average loss: 0.0495 Time : 0m 9s\n",
      "====> Epoch: 125 Average loss: 0.0486 Time : 0m 12s\n",
      "====> Epoch: 126 Average loss: 0.0492 Time : 0m 15s\n",
      "====> Epoch: 127 Average loss: 0.0475 Time : 0m 15s\n",
      "====> Epoch: 128 Average loss: 0.0476 Time : 0m 15s\n",
      "====> Epoch: 129 Average loss: 0.0501 Time : 0m 15s\n",
      "====> Epoch: 130 Average loss: 0.0499 Time : 0m 15s\n",
      "====> Epoch: 131 Average loss: 0.0489 Time : 0m 15s\n",
      "====> Epoch: 132 Average loss: 0.0493 Time : 0m 15s\n",
      "====> Epoch: 133 Average loss: 0.0481 Time : 0m 15s\n",
      "====> Epoch: 134 Average loss: 0.0511 Time : 0m 15s\n",
      "====> Epoch: 135 Average loss: 0.0480 Time : 0m 14s\n",
      "====> Epoch: 136 Average loss: 0.0471 Time : 0m 9s\n",
      "====> Epoch: 137 Average loss: 0.0515 Time : 0m 9s\n",
      "====> Epoch: 138 Average loss: 0.0499 Time : 0m 9s\n",
      "====> Epoch: 139 Average loss: 0.0461 Time : 0m 10s\n",
      "====> Epoch: 140 Average loss: 0.0476 Time : 0m 15s\n",
      "====> Epoch: 141 Average loss: 0.0477 Time : 0m 15s\n",
      "====> Epoch: 142 Average loss: 0.0492 Time : 0m 15s\n",
      "====> Epoch: 143 Average loss: 0.0533 Time : 0m 15s\n",
      "====> Epoch: 144 Average loss: 0.0492 Time : 0m 15s\n",
      "====> Epoch: 145 Average loss: 0.0472 Time : 0m 15s\n",
      "====> Epoch: 146 Average loss: 0.0477 Time : 0m 15s\n",
      "====> Epoch: 147 Average loss: 0.0494 Time : 0m 15s\n",
      "====> Epoch: 148 Average loss: 0.0481 Time : 0m 15s\n",
      "====> Epoch: 149 Average loss: 0.0489 Time : 0m 15s\n",
      "====> Epoch: 150 Average loss: 0.0489 Time : 0m 15s\n",
      "====> Epoch: 151 Average loss: 0.0498 Time : 0m 15s\n",
      "====> Epoch: 152 Average loss: 0.0477 Time : 0m 15s\n",
      "====> Epoch: 153 Average loss: 0.0485 Time : 0m 15s\n",
      "====> Epoch: 154 Average loss: 0.0485 Time : 0m 15s\n",
      "====> Epoch: 155 Average loss: 0.0470 Time : 0m 15s\n",
      "====> Epoch: 156 Average loss: 0.0492 Time : 0m 15s\n",
      "====> Epoch: 157 Average loss: 0.0503 Time : 0m 15s\n",
      "====> Epoch: 158 Average loss: 0.0468 Time : 0m 15s\n",
      "====> Epoch: 159 Average loss: 0.0489 Time : 0m 15s\n",
      "====> Epoch: 160 Average loss: 0.0505 Time : 0m 15s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 161 Average loss: 0.0481 Time : 0m 15s\n",
      "====> Epoch: 162 Average loss: 0.0475 Time : 0m 15s\n",
      "====> Epoch: 163 Average loss: 0.0504 Time : 0m 15s\n",
      "====> Epoch: 164 Average loss: 0.0478 Time : 0m 15s\n",
      "====> Epoch: 165 Average loss: 0.0482 Time : 0m 15s\n",
      "====> Epoch: 166 Average loss: 0.0482 Time : 0m 15s\n",
      "====> Epoch: 167 Average loss: 0.0480 Time : 0m 15s\n",
      "====> Epoch: 168 Average loss: 0.0488 Time : 0m 15s\n",
      "====> Epoch: 169 Average loss: 0.0488 Time : 0m 15s\n",
      "====> Epoch: 170 Average loss: 0.0481 Time : 0m 15s\n",
      "====> Epoch: 171 Average loss: 0.0502 Time : 0m 15s\n",
      "====> Epoch: 172 Average loss: 0.0471 Time : 0m 15s\n",
      "====> Epoch: 173 Average loss: 0.0470 Time : 0m 15s\n",
      "====> Epoch: 174 Average loss: 0.0504 Time : 0m 15s\n",
      "====> Epoch: 175 Average loss: 0.0505 Time : 0m 11s\n",
      "====> Epoch: 176 Average loss: 0.0480 Time : 0m 10s\n",
      "====> Epoch: 177 Average loss: 0.0483 Time : 0m 13s\n",
      "====> Epoch: 178 Average loss: 0.0474 Time : 0m 15s\n",
      "====> Epoch: 179 Average loss: 0.0470 Time : 0m 12s\n",
      "====> Epoch: 180 Average loss: 0.0510 Time : 0m 9s\n",
      "====> Epoch: 181 Average loss: 0.0492 Time : 0m 9s\n",
      "====> Epoch: 182 Average loss: 0.0466 Time : 0m 10s\n",
      "====> Epoch: 183 Average loss: 0.0493 Time : 0m 9s\n",
      "====> Epoch: 184 Average loss: 0.0487 Time : 0m 11s\n",
      "====> Epoch: 185 Average loss: 0.0469 Time : 0m 15s\n",
      "====> Epoch: 186 Average loss: 0.0480 Time : 0m 15s\n",
      "====> Epoch: 187 Average loss: 0.0482 Time : 0m 14s\n",
      "====> Epoch: 188 Average loss: 0.0513 Time : 0m 15s\n",
      "====> Epoch: 189 Average loss: 0.0519 Time : 0m 15s\n",
      "====> Epoch: 190 Average loss: 0.0479 Time : 0m 15s\n",
      "====> Epoch: 191 Average loss: 0.0473 Time : 0m 15s\n",
      "====> Epoch: 192 Average loss: 0.0481 Time : 0m 15s\n",
      "====> Epoch: 193 Average loss: 0.0487 Time : 0m 13s\n",
      "====> Epoch: 194 Average loss: 0.0477 Time : 0m 11s\n",
      "====> Epoch: 195 Average loss: 0.0464 Time : 0m 11s\n",
      "====> Epoch: 196 Average loss: 0.0479 Time : 0m 10s\n",
      "====> Epoch: 197 Average loss: 0.0505 Time : 0m 10s\n",
      "====> Epoch: 198 Average loss: 0.0480 Time : 0m 10s\n",
      "====> Epoch: 199 Average loss: 0.0473 Time : 0m 11s\n",
      "====> Epoch: 200 Average loss: 0.0471 Time : 0m 11s\n",
      "====> Epoch: 201 Average loss: 0.0502 Time : 0m 10s\n",
      "====> Epoch: 202 Average loss: 0.0480 Time : 0m 11s\n",
      "====> Epoch: 203 Average loss: 0.0459 Time : 0m 11s\n",
      "====> Epoch: 204 Average loss: 0.0490 Time : 0m 10s\n",
      "====> Epoch: 205 Average loss: 0.0481 Time : 0m 10s\n",
      "====> Epoch: 206 Average loss: 0.0471 Time : 0m 10s\n",
      "====> Epoch: 207 Average loss: 0.0498 Time : 0m 10s\n",
      "====> Epoch: 208 Average loss: 0.0478 Time : 0m 10s\n",
      "====> Epoch: 209 Average loss: 0.0457 Time : 0m 10s\n",
      "====> Epoch: 210 Average loss: 0.0488 Time : 0m 10s\n",
      "====> Epoch: 211 Average loss: 0.0475 Time : 0m 10s\n",
      "====> Epoch: 212 Average loss: 0.0483 Time : 0m 10s\n",
      "====> Epoch: 213 Average loss: 0.0471 Time : 0m 10s\n",
      "====> Epoch: 214 Average loss: 0.0487 Time : 0m 10s\n",
      "====> Epoch: 215 Average loss: 0.0482 Time : 0m 10s\n",
      "====> Epoch: 216 Average loss: 0.0468 Time : 0m 10s\n",
      "====> Epoch: 217 Average loss: 0.0485 Time : 0m 10s\n",
      "====> Epoch: 218 Average loss: 0.0479 Time : 0m 10s\n",
      "====> Epoch: 219 Average loss: 0.0490 Time : 0m 10s\n",
      "====> Epoch: 220 Average loss: 0.0483 Time : 0m 10s\n",
      "====> Epoch: 221 Average loss: 0.0544 Time : 0m 11s\n",
      "====> Epoch: 222 Average loss: 0.0462 Time : 0m 10s\n",
      "====> Epoch: 223 Average loss: 0.0452 Time : 0m 10s\n",
      "====> Epoch: 224 Average loss: 0.0517 Time : 0m 10s\n",
      "====> Epoch: 225 Average loss: 0.0485 Time : 0m 10s\n",
      "====> Epoch: 226 Average loss: 0.0482 Time : 0m 9s\n",
      "====> Epoch: 227 Average loss: 0.0459 Time : 0m 9s\n",
      "====> Epoch: 228 Average loss: 0.0481 Time : 0m 10s\n",
      "====> Epoch: 229 Average loss: 0.0479 Time : 0m 10s\n",
      "====> Epoch: 230 Average loss: 0.0479 Time : 0m 10s\n",
      "====> Epoch: 231 Average loss: 0.0481 Time : 0m 10s\n",
      "====> Epoch: 232 Average loss: 0.0482 Time : 0m 10s\n",
      "====> Epoch: 233 Average loss: 0.0491 Time : 0m 10s\n",
      "====> Epoch: 234 Average loss: 0.0469 Time : 0m 10s\n",
      "====> Epoch: 235 Average loss: 0.0472 Time : 0m 10s\n",
      "====> Epoch: 236 Average loss: 0.0477 Time : 0m 10s\n",
      "====> Epoch: 237 Average loss: 0.0472 Time : 0m 10s\n",
      "====> Epoch: 238 Average loss: 0.0479 Time : 0m 10s\n",
      "====> Epoch: 239 Average loss: 0.0489 Time : 0m 10s\n",
      "====> Epoch: 240 Average loss: 0.0460 Time : 0m 10s\n",
      "====> Epoch: 241 Average loss: 0.0514 Time : 0m 10s\n",
      "====> Epoch: 242 Average loss: 0.0479 Time : 0m 10s\n",
      "====> Epoch: 243 Average loss: 0.0485 Time : 0m 10s\n",
      "====> Epoch: 244 Average loss: 0.0481 Time : 0m 10s\n",
      "====> Epoch: 245 Average loss: 0.0456 Time : 0m 10s\n",
      "====> Epoch: 246 Average loss: 0.0487 Time : 0m 10s\n",
      "====> Epoch: 247 Average loss: 0.0465 Time : 0m 10s\n",
      "====> Epoch: 248 Average loss: 0.0501 Time : 0m 10s\n",
      "====> Epoch: 249 Average loss: 0.0475 Time : 0m 10s\n",
      "====> Epoch: 250 Average loss: 0.0456 Time : 0m 10s\n",
      "====> Epoch: 251 Average loss: 0.0461 Time : 0m 9s\n",
      "====> Epoch: 252 Average loss: 0.0521 Time : 0m 9s\n",
      "====> Epoch: 253 Average loss: 0.0468 Time : 0m 10s\n",
      "====> Epoch: 254 Average loss: 0.0465 Time : 0m 9s\n",
      "====> Epoch: 255 Average loss: 0.0469 Time : 0m 10s\n",
      "====> Epoch: 256 Average loss: 0.0489 Time : 0m 10s\n",
      "====> Epoch: 257 Average loss: 0.0460 Time : 0m 10s\n",
      "====> Epoch: 258 Average loss: 0.0480 Time : 0m 10s\n",
      "====> Epoch: 259 Average loss: 0.0480 Time : 0m 10s\n",
      "====> Epoch: 260 Average loss: 0.0465 Time : 0m 10s\n",
      "====> Epoch: 261 Average loss: 0.0478 Time : 0m 10s\n",
      "====> Epoch: 262 Average loss: 0.0477 Time : 0m 10s\n",
      "====> Epoch: 263 Average loss: 0.0469 Time : 0m 10s\n",
      "====> Epoch: 264 Average loss: 0.0482 Time : 0m 10s\n",
      "====> Epoch: 265 Average loss: 0.0503 Time : 0m 10s\n",
      "====> Epoch: 266 Average loss: 0.0459 Time : 0m 10s\n",
      "====> Epoch: 267 Average loss: 0.0478 Time : 0m 10s\n",
      "====> Epoch: 268 Average loss: 0.0462 Time : 0m 10s\n",
      "====> Epoch: 269 Average loss: 0.0479 Time : 0m 10s\n",
      "====> Epoch: 270 Average loss: 0.0493 Time : 0m 9s\n",
      "====> Epoch: 271 Average loss: 0.0467 Time : 0m 10s\n",
      "====> Epoch: 272 Average loss: 0.0460 Time : 0m 10s\n",
      "====> Epoch: 273 Average loss: 0.0466 Time : 0m 10s\n",
      "====> Epoch: 274 Average loss: 0.0490 Time : 0m 10s\n",
      "====> Epoch: 275 Average loss: 0.0483 Time : 0m 10s\n",
      "====> Epoch: 276 Average loss: 0.0462 Time : 0m 10s\n",
      "====> Epoch: 277 Average loss: 0.0467 Time : 0m 10s\n",
      "====> Epoch: 278 Average loss: 0.0491 Time : 0m 10s\n",
      "====> Epoch: 279 Average loss: 0.0501 Time : 0m 9s\n",
      "====> Epoch: 280 Average loss: 0.0481 Time : 0m 10s\n",
      "====> Epoch: 281 Average loss: 0.0449 Time : 0m 10s\n",
      "====> Epoch: 282 Average loss: 0.0461 Time : 0m 10s\n",
      "====> Epoch: 283 Average loss: 0.0486 Time : 0m 9s\n",
      "====> Epoch: 284 Average loss: 0.0471 Time : 0m 11s\n",
      "====> Epoch: 285 Average loss: 0.0463 Time : 0m 10s\n",
      "====> Epoch: 286 Average loss: 0.0495 Time : 0m 10s\n",
      "====> Epoch: 287 Average loss: 0.0463 Time : 0m 9s\n",
      "====> Epoch: 288 Average loss: 0.0468 Time : 0m 10s\n",
      "====> Epoch: 289 Average loss: 0.0474 Time : 0m 10s\n",
      "====> Epoch: 290 Average loss: 0.0490 Time : 0m 10s\n",
      "====> Epoch: 291 Average loss: 0.0483 Time : 0m 10s\n",
      "====> Epoch: 292 Average loss: 0.0455 Time : 0m 10s\n",
      "====> Epoch: 293 Average loss: 0.0462 Time : 0m 10s\n",
      "====> Epoch: 294 Average loss: 0.0481 Time : 0m 10s\n",
      "====> Epoch: 295 Average loss: 0.0482 Time : 0m 10s\n",
      "====> Epoch: 296 Average loss: 0.0464 Time : 0m 10s\n",
      "====> Epoch: 297 Average loss: 0.0482 Time : 0m 9s\n",
      "====> Epoch: 298 Average loss: 0.0463 Time : 0m 10s\n",
      "====> Epoch: 299 Average loss: 0.0479 Time : 0m 10s\n",
      "====> Epoch: 300 Average loss: 0.0476 Time : 0m 10s\n",
      "====> Epoch: 301 Average loss: 0.0456 Time : 0m 10s\n",
      "====> Epoch: 302 Average loss: 0.0454 Time : 0m 10s\n",
      "====> Epoch: 303 Average loss: 0.0477 Time : 0m 10s\n",
      "====> Epoch: 304 Average loss: 0.0504 Time : 0m 10s\n",
      "====> Epoch: 305 Average loss: 0.0473 Time : 0m 10s\n",
      "====> Epoch: 306 Average loss: 0.0446 Time : 0m 10s\n",
      "====> Epoch: 307 Average loss: 0.0481 Time : 0m 9s\n",
      "====> Epoch: 308 Average loss: 0.0474 Time : 0m 10s\n",
      "====> Epoch: 309 Average loss: 0.0463 Time : 0m 10s\n",
      "====> Epoch: 310 Average loss: 0.0477 Time : 0m 10s\n",
      "====> Epoch: 311 Average loss: 0.0467 Time : 0m 10s\n",
      "====> Epoch: 312 Average loss: 0.0466 Time : 0m 9s\n",
      "====> Epoch: 313 Average loss: 0.0470 Time : 0m 10s\n",
      "====> Epoch: 314 Average loss: 0.0494 Time : 0m 10s\n",
      "====> Epoch: 315 Average loss: 0.0462 Time : 0m 10s\n",
      "====> Epoch: 316 Average loss: 0.0457 Time : 0m 10s\n",
      "====> Epoch: 317 Average loss: 0.0459 Time : 0m 10s\n",
      "====> Epoch: 318 Average loss: 0.0493 Time : 0m 10s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 319 Average loss: 0.0465 Time : 0m 10s\n",
      "====> Epoch: 320 Average loss: 0.0464 Time : 0m 10s\n",
      "====> Epoch: 321 Average loss: 0.0486 Time : 0m 10s\n",
      "====> Epoch: 322 Average loss: 0.0466 Time : 0m 10s\n",
      "====> Epoch: 323 Average loss: 0.0462 Time : 0m 9s\n",
      "====> Epoch: 324 Average loss: 0.0484 Time : 0m 10s\n",
      "====> Epoch: 325 Average loss: 0.0460 Time : 0m 10s\n",
      "====> Epoch: 326 Average loss: 0.0462 Time : 0m 10s\n",
      "====> Epoch: 327 Average loss: 0.0480 Time : 0m 10s\n",
      "====> Epoch: 328 Average loss: 0.0476 Time : 0m 10s\n",
      "====> Epoch: 329 Average loss: 0.0469 Time : 0m 10s\n",
      "====> Epoch: 330 Average loss: 0.0456 Time : 0m 10s\n",
      "====> Epoch: 331 Average loss: 0.0482 Time : 0m 9s\n",
      "====> Epoch: 332 Average loss: 0.0484 Time : 0m 10s\n",
      "====> Epoch: 333 Average loss: 0.0461 Time : 0m 10s\n",
      "====> Epoch: 334 Average loss: 0.0451 Time : 0m 10s\n",
      "====> Epoch: 335 Average loss: 0.0472 Time : 0m 10s\n",
      "====> Epoch: 336 Average loss: 0.0495 Time : 0m 10s\n",
      "====> Epoch: 337 Average loss: 0.0454 Time : 0m 10s\n",
      "====> Epoch: 338 Average loss: 0.0465 Time : 0m 10s\n",
      "====> Epoch: 339 Average loss: 0.0463 Time : 0m 10s\n",
      "====> Epoch: 340 Average loss: 0.0463 Time : 0m 10s\n",
      "====> Epoch: 341 Average loss: 0.0476 Time : 0m 10s\n",
      "====> Epoch: 342 Average loss: 0.0468 Time : 0m 10s\n",
      "====> Epoch: 343 Average loss: 0.0468 Time : 0m 10s\n",
      "====> Epoch: 344 Average loss: 0.0463 Time : 0m 10s\n",
      "====> Epoch: 345 Average loss: 0.0461 Time : 0m 10s\n",
      "====> Epoch: 346 Average loss: 0.0463 Time : 0m 10s\n",
      "====> Epoch: 347 Average loss: 0.0568 Time : 0m 10s\n",
      "====> Epoch: 348 Average loss: 0.0466 Time : 0m 10s\n",
      "====> Epoch: 349 Average loss: 0.0443 Time : 0m 10s\n",
      "====> Epoch: 350 Average loss: 0.0457 Time : 0m 10s\n",
      "====> Epoch: 351 Average loss: 0.0455 Time : 0m 10s\n",
      "====> Epoch: 352 Average loss: 0.0476 Time : 0m 10s\n",
      "====> Epoch: 353 Average loss: 0.0508 Time : 0m 12s\n",
      "====> Epoch: 354 Average loss: 0.0473 Time : 0m 11s\n",
      "====> Epoch: 355 Average loss: 0.0441 Time : 0m 12s\n",
      "====> Epoch: 356 Average loss: 0.0451 Time : 0m 11s\n",
      "====> Epoch: 357 Average loss: 0.0467 Time : 0m 11s\n",
      "====> Epoch: 358 Average loss: 0.0478 Time : 0m 12s\n",
      "====> Epoch: 359 Average loss: 0.0483 Time : 0m 10s\n",
      "====> Epoch: 360 Average loss: 0.0462 Time : 0m 9s\n",
      "====> Epoch: 361 Average loss: 0.0448 Time : 0m 9s\n",
      "====> Epoch: 362 Average loss: 0.0457 Time : 0m 11s\n",
      "====> Epoch: 363 Average loss: 0.0476 Time : 0m 12s\n",
      "====> Epoch: 364 Average loss: 0.0482 Time : 0m 9s\n",
      "====> Epoch: 365 Average loss: 0.0483 Time : 0m 9s\n",
      "====> Epoch: 366 Average loss: 0.0459 Time : 0m 10s\n",
      "====> Epoch: 367 Average loss: 0.0468 Time : 0m 12s\n",
      "====> Epoch: 368 Average loss: 0.0503 Time : 0m 10s\n",
      "====> Epoch: 369 Average loss: 0.0448 Time : 0m 11s\n",
      "====> Epoch: 370 Average loss: 0.0451 Time : 0m 11s\n",
      "====> Epoch: 371 Average loss: 0.0469 Time : 0m 12s\n",
      "====> Epoch: 372 Average loss: 0.0492 Time : 0m 12s\n",
      "====> Epoch: 373 Average loss: 0.0474 Time : 0m 10s\n",
      "====> Epoch: 374 Average loss: 0.0452 Time : 0m 12s\n",
      "====> Epoch: 375 Average loss: 0.0501 Time : 0m 12s\n",
      "====> Epoch: 376 Average loss: 0.0464 Time : 0m 11s\n",
      "====> Epoch: 377 Average loss: 0.0439 Time : 0m 12s\n",
      "====> Epoch: 378 Average loss: 0.0458 Time : 0m 12s\n",
      "====> Epoch: 379 Average loss: 0.0465 Time : 0m 12s\n",
      "====> Epoch: 380 Average loss: 0.0497 Time : 0m 12s\n",
      "====> Epoch: 381 Average loss: 0.0473 Time : 0m 12s\n",
      "====> Epoch: 382 Average loss: 0.0453 Time : 0m 10s\n",
      "====> Epoch: 383 Average loss: 0.0451 Time : 0m 11s\n",
      "====> Epoch: 384 Average loss: 0.0458 Time : 0m 9s\n",
      "====> Epoch: 385 Average loss: 0.0490 Time : 0m 9s\n",
      "====> Epoch: 386 Average loss: 0.0455 Time : 0m 12s\n",
      "====> Epoch: 387 Average loss: 0.0458 Time : 0m 9s\n",
      "====> Epoch: 388 Average loss: 0.0465 Time : 0m 12s\n",
      "====> Epoch: 389 Average loss: 0.0469 Time : 0m 12s\n",
      "====> Epoch: 390 Average loss: 0.0466 Time : 0m 12s\n",
      "====> Epoch: 391 Average loss: 0.0473 Time : 0m 12s\n",
      "====> Epoch: 392 Average loss: 0.0474 Time : 0m 9s\n",
      "====> Epoch: 393 Average loss: 0.0465 Time : 0m 9s\n",
      "====> Epoch: 394 Average loss: 0.0458 Time : 0m 9s\n",
      "====> Epoch: 395 Average loss: 0.0458 Time : 0m 11s\n",
      "====> Epoch: 396 Average loss: 0.0491 Time : 0m 12s\n",
      "====> Epoch: 397 Average loss: 0.0453 Time : 0m 13s\n",
      "====> Epoch: 398 Average loss: 0.0446 Time : 0m 12s\n",
      "====> Epoch: 399 Average loss: 0.0475 Time : 0m 12s\n",
      "====> Epoch: 400 Average loss: 0.0459 Time : 0m 11s\n",
      "====> Epoch: 401 Average loss: 0.0478 Time : 0m 10s\n",
      "====> Epoch: 402 Average loss: 0.0464 Time : 0m 11s\n",
      "====> Epoch: 403 Average loss: 0.0449 Time : 0m 9s\n",
      "====> Epoch: 404 Average loss: 0.0504 Time : 0m 9s\n",
      "====> Epoch: 405 Average loss: 0.0459 Time : 0m 10s\n",
      "====> Epoch: 406 Average loss: 0.0448 Time : 0m 11s\n",
      "====> Epoch: 407 Average loss: 0.0453 Time : 0m 12s\n",
      "====> Epoch: 408 Average loss: 0.0487 Time : 0m 11s\n",
      "====> Epoch: 409 Average loss: 0.0463 Time : 0m 12s\n",
      "====> Epoch: 410 Average loss: 0.0450 Time : 0m 11s\n",
      "====> Epoch: 411 Average loss: 0.0458 Time : 0m 11s\n",
      "====> Epoch: 412 Average loss: 0.0468 Time : 0m 10s\n",
      "====> Epoch: 413 Average loss: 0.0480 Time : 0m 10s\n",
      "====> Epoch: 414 Average loss: 0.0452 Time : 0m 9s\n",
      "====> Epoch: 415 Average loss: 0.0464 Time : 0m 9s\n",
      "====> Epoch: 416 Average loss: 0.0463 Time : 0m 11s\n",
      "====> Epoch: 417 Average loss: 0.0461 Time : 0m 11s\n",
      "====> Epoch: 418 Average loss: 0.0472 Time : 0m 12s\n",
      "====> Epoch: 419 Average loss: 0.0467 Time : 0m 12s\n",
      "====> Epoch: 420 Average loss: 0.0470 Time : 0m 12s\n",
      "====> Epoch: 421 Average loss: 0.0493 Time : 0m 12s\n",
      "====> Epoch: 422 Average loss: 0.0448 Time : 0m 11s\n",
      "====> Epoch: 423 Average loss: 0.0459 Time : 0m 11s\n",
      "====> Epoch: 424 Average loss: 0.0464 Time : 0m 12s\n",
      "====> Epoch: 425 Average loss: 0.0474 Time : 0m 12s\n",
      "====> Epoch: 426 Average loss: 0.0459 Time : 0m 12s\n",
      "====> Epoch: 427 Average loss: 0.0449 Time : 0m 12s\n",
      "====> Epoch: 428 Average loss: 0.0457 Time : 0m 9s\n",
      "====> Epoch: 429 Average loss: 0.0491 Time : 0m 9s\n",
      "====> Epoch: 430 Average loss: 0.0453 Time : 0m 10s\n",
      "====> Epoch: 431 Average loss: 0.0458 Time : 0m 10s\n",
      "====> Epoch: 432 Average loss: 0.0469 Time : 0m 9s\n",
      "====> Epoch: 433 Average loss: 0.0477 Time : 0m 9s\n",
      "====> Epoch: 434 Average loss: 0.0482 Time : 0m 9s\n",
      "====> Epoch: 435 Average loss: 0.0467 Time : 0m 11s\n",
      "====> Epoch: 436 Average loss: 0.0457 Time : 0m 10s\n",
      "====> Epoch: 437 Average loss: 0.0446 Time : 0m 9s\n",
      "====> Epoch: 438 Average loss: 0.0458 Time : 0m 9s\n",
      "====> Epoch: 439 Average loss: 0.0455 Time : 0m 9s\n",
      "====> Epoch: 440 Average loss: 0.0465 Time : 0m 10s\n",
      "====> Epoch: 441 Average loss: 0.0501 Time : 0m 11s\n",
      "====> Epoch: 442 Average loss: 0.0464 Time : 0m 11s\n",
      "====> Epoch: 443 Average loss: 0.0440 Time : 0m 10s\n",
      "====> Epoch: 444 Average loss: 0.0456 Time : 0m 11s\n",
      "====> Epoch: 445 Average loss: 0.0476 Time : 0m 12s\n",
      "====> Epoch: 446 Average loss: 0.0455 Time : 0m 12s\n",
      "====> Epoch: 447 Average loss: 0.0458 Time : 0m 12s\n",
      "====> Epoch: 448 Average loss: 0.0450 Time : 0m 11s\n",
      "====> Epoch: 449 Average loss: 0.0479 Time : 0m 10s\n",
      "====> Epoch: 450 Average loss: 0.0469 Time : 0m 10s\n",
      "====> Epoch: 451 Average loss: 0.0494 Time : 0m 9s\n",
      "====> Epoch: 452 Average loss: 0.0460 Time : 0m 10s\n",
      "====> Epoch: 453 Average loss: 0.0447 Time : 0m 12s\n",
      "====> Epoch: 454 Average loss: 0.0460 Time : 0m 12s\n",
      "====> Epoch: 455 Average loss: 0.0457 Time : 0m 12s\n",
      "====> Epoch: 456 Average loss: 0.0503 Time : 0m 9s\n",
      "====> Epoch: 457 Average loss: 0.0454 Time : 0m 11s\n",
      "====> Epoch: 458 Average loss: 0.0463 Time : 0m 12s\n",
      "====> Epoch: 459 Average loss: 0.0476 Time : 0m 9s\n",
      "====> Epoch: 460 Average loss: 0.0444 Time : 0m 9s\n",
      "====> Epoch: 461 Average loss: 0.0437 Time : 0m 10s\n",
      "====> Epoch: 462 Average loss: 0.0463 Time : 0m 11s\n",
      "====> Epoch: 463 Average loss: 0.0460 Time : 0m 9s\n",
      "====> Epoch: 464 Average loss: 0.0465 Time : 0m 9s\n",
      "====> Epoch: 465 Average loss: 0.0465 Time : 0m 9s\n",
      "====> Epoch: 466 Average loss: 0.0458 Time : 0m 11s\n",
      "====> Epoch: 467 Average loss: 0.0470 Time : 0m 12s\n",
      "====> Epoch: 468 Average loss: 0.0458 Time : 0m 11s\n",
      "====> Epoch: 469 Average loss: 0.0468 Time : 0m 11s\n",
      "====> Epoch: 470 Average loss: 0.0457 Time : 0m 12s\n",
      "====> Epoch: 471 Average loss: 0.0456 Time : 0m 10s\n",
      "====> Epoch: 472 Average loss: 0.0453 Time : 0m 13s\n",
      "====> Epoch: 473 Average loss: 0.0451 Time : 0m 15s\n",
      "====> Epoch: 474 Average loss: 0.0458 Time : 0m 14s\n",
      "====> Epoch: 475 Average loss: 0.0461 Time : 0m 11s\n",
      "====> Epoch: 476 Average loss: 0.0454 Time : 0m 9s\n",
      "====> Epoch: 477 Average loss: 0.0463 Time : 0m 9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 478 Average loss: 0.0471 Time : 0m 11s\n",
      "====> Epoch: 479 Average loss: 0.0464 Time : 0m 15s\n",
      "====> Epoch: 480 Average loss: 0.0447 Time : 0m 11s\n",
      "====> Epoch: 481 Average loss: 0.0459 Time : 0m 9s\n",
      "====> Epoch: 482 Average loss: 0.0471 Time : 0m 9s\n",
      "====> Epoch: 483 Average loss: 0.0475 Time : 0m 9s\n",
      "====> Epoch: 484 Average loss: 0.0448 Time : 0m 10s\n",
      "====> Epoch: 485 Average loss: 0.0441 Time : 0m 9s\n",
      "====> Epoch: 486 Average loss: 0.0469 Time : 0m 9s\n",
      "====> Epoch: 487 Average loss: 0.0450 Time : 0m 9s\n",
      "====> Epoch: 488 Average loss: 0.0444 Time : 0m 10s\n",
      "====> Epoch: 489 Average loss: 0.0477 Time : 0m 15s\n",
      "====> Epoch: 490 Average loss: 0.0462 Time : 0m 15s\n",
      "====> Epoch: 491 Average loss: 0.0468 Time : 0m 14s\n",
      "====> Epoch: 492 Average loss: 0.0450 Time : 0m 13s\n",
      "====> Epoch: 493 Average loss: 0.0461 Time : 0m 12s\n",
      "====> Epoch: 494 Average loss: 0.0458 Time : 0m 12s\n",
      "====> Epoch: 495 Average loss: 0.0459 Time : 0m 14s\n",
      "====> Epoch: 496 Average loss: 0.0478 Time : 0m 10s\n",
      "====> Epoch: 497 Average loss: 0.0475 Time : 0m 11s\n",
      "====> Epoch: 498 Average loss: 0.0438 Time : 0m 10s\n",
      "====> Epoch: 499 Average loss: 0.0444 Time : 0m 13s\n"
     ]
    }
   ],
   "source": [
    "train_losses = []\n",
    "iterations = 500\n",
    "for i in range(iterations):\n",
    "    train_losses.append(train(i))\n",
    "torch.save(haha,'./blur1.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ldlXtma-JLlJ"
   },
   "outputs": [],
   "source": [
    "path = '/home/cvgws2/juniors_blur/test'\n",
    "for file in os.listdir(path):\n",
    "    image = Image.open(os.path.join(path,file))\n",
    "    image = apply_transform(image).float()\n",
    "    image = Variable(image, requires_grad=True)\n",
    "    image = image.unsqueeze(0)\n",
    "    if use_gpu:\n",
    "        inputs = Variable(image).cuda()\n",
    "    else:\n",
    "        inputs = Variable(image)\n",
    "    recon_,_,_,_ = haha(inputs)\n",
    "    comparison = recon_.view(1, 1, 256, 256)[0]\n",
    "    save_image(comparison.cpu(),os.path.join('/home/cvgws2/juniors_blur/results',file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 280
    },
    "colab_type": "code",
    "id": "-qx4y4RPR6gL",
    "outputId": "d3d532f7-1d9b-4ac9-e8cc-1fc4e909ec8c"
   },
   "outputs": [],
   "source": [
    "image = Image.open('/home/cvgws2/juniors_blur/images1.jpeg')\n",
    "image = apply_transform(image).float()\n",
    "image = Variable(image, requires_grad=True)\n",
    "image = image.unsqueeze(0)\n",
    "if use_gpu:\n",
    "    inputs = Variable(image).cuda()\n",
    "else:\n",
    "    inputs = Variable(image)\n",
    "recon_,_,_,_ = haha(inputs)\n",
    "comparison = recon_.view(1, 1, 256, 256)[0]\n",
    "save_image(comparison.cpu(),'/home/cvgws2/juniors_blur/trial1.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Copy of Blur_1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
